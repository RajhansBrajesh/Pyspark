from pyspark.sql.functions import schems_of_json, col, from_json

Json_schema_df = df_orderraw.select(schema_of_json(col("value")).alias("json_schema"))
json_schema = json_schema_df.collect()[0]["json_schema"]

# infamous way used in Hybris with RDD
Json_schema_df = spark.read.json(df_orderraw.rdd.map(lambda row: row.value))
dynemic_json_schema = Json_schema_df.schema

# use from_json to convert json to df col
df2 = df_orderraw.selectExpr('value').withColumn("jsonData", from_json(col("value"),dynemic_json_schema)

# To create temp view from df 
df2.createOrReplaceTempView('orderData')

#transformation:
df6 = df.withColumn(
    "segment",
    when((col("age") > 22) & (col("name") != "Bob"), "Group A")
    .otherwise("Group B")
)
