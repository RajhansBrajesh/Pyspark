from pyspark.sql.functions import schems_of_json, col, from_json

Json_schema_df = df_orderraw.select(schema_of_json(col("value")).alias("json_schema"))
json_schema = json_schema_df.collect()[0]["json_schema"]

# infamous way used in Hybris with RDD
Json_schema_df = spark.read.json(df_orderraw.rdd.map(lambda row: row.value))
dynemic_json_schema = Json_schema_df.schema

# use from_json to convert json to df col
df2 = df_orderraw.selectExpr('value').withColumn("jsonData", from_json(col("value"),dynemic_json_schema)

# To create temp view from df 
df2.createOrReplaceTempView('orderData')

#transformation:
df6 = df.withColumn(
    "segment",
    when((col("age") > 22) & (col("name") != "Bob"), "Group A")
    .otherwise("Group B")
)

# To Flatten any df having json in one of the col. ref: https://www.youtube.com/watch?v=jD8JIw1FVVg&t=453s

def flatten(df):
   compute Complex Fields (Lists and Structs) in Schema   
   complex_fields = dict([(field.name, field.dataType)
                             for field in df.schema.fields
                             if type(field.dataType) == ArrayType or  type(field.dataType) == StructType])
   while len(complex_fields)!=0:
      col_name=list(complex_fields.keys())[0]
      print ("Processing :"+col_name+" Type : "+str(type(complex_fields[col_name])))
    
      #if StructType then convert all sub element to columns.
      #i.e. flatten structs
      if (type(complex_fields[col_name]) == StructType):
         expanded = [col(col_name+'.'+k).alias(col_name+'_'+k) for k in [ n.name for n in  complex_fields[col_name]]]
         df=df.select("*", *expanded).drop(col_name)
    
      #if ArrayType then add the Array Elements as Rows using the explode function
      #i.e. explode Arrays
      elif (type(complex_fields[col_name]) == ArrayType):    
         df=df.withColumn(col_name,explode_outer(col_name))
    
      recompute remaining Complex Fields in Schema       
      complex_fields = dict([(field.name, field.dataType)
                             for field in df.schema.fields
                             if type(field.dataType) == ArrayType or  type(field.dataType) == StructType])
   return df


